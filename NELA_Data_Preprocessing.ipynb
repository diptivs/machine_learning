{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NELA_Data_Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diptivs/machine_learning/blob/master/NELA_Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ngdv_58Hj4G",
        "colab_type": "text"
      },
      "source": [
        "SJSU ML 2019 : CMPE 257"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SRWLhh0Jb3i",
        "colab_type": "text"
      },
      "source": [
        "Professor: Dr. Arsanjani\n",
        "\n",
        "Team: Cloud_stocks\n",
        "\n",
        "Members: \n",
        "* Dipti Shiralkar\n",
        "* Parvizsho Aminov\n",
        "* Meghana Yoganarasimha\n",
        "* Navjot Bola "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFuwnvlsJiUB",
        "colab_type": "text"
      },
      "source": [
        "#Details of dataset and notes:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFIhJFynRPN1",
        "colab_type": "text"
      },
      "source": [
        "**Datasets used:**\n",
        "* We used NELA datasets available here: https://dataverse.harvard.edu/dataverse/nela\n",
        "* Used 2018 dataset for rest of the features\n",
        "* Used 2017 dataset to prepare a model for \"Posts/Social Activities\". *[ As Scraper code is changed. 2017 data file has full HTML with all tags which made social media (Facebook) data was available. But 2018 data files just have the articles]*\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wznHoPNJ-TV0",
        "colab_type": "text"
      },
      "source": [
        "**Refernces:**\n",
        "\n",
        "* https://arxiv.org/pdf/1803.10124.pdf  --> to understand the feature extraction done on 2017 dataset\n",
        "* https://arxiv.org/pdf/1904.01546.pdf --> to understand the Labels.csv better\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ftx3oEBAarc",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-chEpebZ4rD",
        "colab_type": "code",
        "outputId": "c257a562-0e6d-431a-ca9f-4f0a24671cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import sqlite3\n",
        "import string\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy import sparse\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_MostNVAmyB",
        "colab_type": "text"
      },
      "source": [
        "#Load the dataset DB file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifLreIzNYoJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup google auth\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNDc8vwwYqvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for fname,fid in {\"articles.db\":\"1K6XNG1N67fJhv65LshmT8PZIUPk61o_0\"}.items():\n",
        "  downloaded = drive.CreateFile({'id':fid}) \n",
        "  downloaded.GetContentFile(fname)\n",
        "  articles_db =  'articles.db'\n",
        "  con = sqlite3.connect(articles_db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BogiygKKBus_",
        "colab_type": "text"
      },
      "source": [
        "#Data preparation\n",
        "\n",
        "Amalgamated + filtered final dataset is available here: nela_score_values_reduced_ds.csv : https://drive.google.com/open?id=1-MdGo8vMMLWMZBcb_K0dKz56FzNEra7W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFl6H-WNndKp",
        "colab_type": "text"
      },
      "source": [
        "### Exclude Sources for which Labels are not available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkN3--ogAyWK",
        "colab_type": "text"
      },
      "source": [
        "List of Unlabelled resources: https://drive.google.com/open?id=1ZqH4iHU8DQiNTEvZuQB7RYy5fVZLqAW7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbrb6qAGbfKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def execute_sql_cmd(statement):\n",
        "  filtered_data = pd.read_sql_query(statement,con)\n",
        "  return filtered_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAd8NzCNh2iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "excluded_sources = ('Anonymous Conservative', 'BBC UK', 'Channel 4 UK', 'Common Dreams', 'Conservative Tribune', 'Crikey', 'Delaware Liberal', 'Dick Morris Blog', 'Fort Russ', 'Freedom-Bunker', 'Hit and Run', 'Hullabaloo Blog', 'Informnapalm', 'JewWorldOrder', 'LabourList', 'Liberal Democrat Voice' ,'Losercom', 'Mail', 'Mint Press News', 'Newsnet Scotland', 'Newswars', 'OSCE', 'Politicalite', 'Politicscouk', 'Prepare For Change', 'Slugger OToole', 'The Daily Blog', 'The Daily Echo', 'The Gaurdian UK', 'The Huffington Post UK', 'The Inquisitr', 'The Manchested Evening News', 'The Week UK', 'Trump Times', 'Unian', 'Window on Eurasia Blog', 'Wizbang', 'rferl', 'theRussophileorg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeluz0g6YUka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_data = execute_sql_cmd(\"select * from articles where source not in ('Anonymous Conservative', 'BBC UK', 'Channel 4 UK', 'Common Dreams', 'Conservative Tribune', 'Crikey', 'Delaware Liberal', 'Dick Morris Blog', 'Fort Russ', 'Freedom-Bunker', 'Hit and Run', 'Hullabaloo Blog', 'Informnapalm', 'JewWorldOrder', 'LabourList', 'Liberal Democrat Voice' ,'Losercom', 'Mail', 'Mint Press News', 'Newsnet Scotland', 'Newswars', 'OSCE', 'Politicalite', 'Politicscouk', 'Prepare For Change', 'Slugger OToole', 'The Daily Blog', 'The Daily Echo', 'The Gaurdian UK', 'The Huffington Post UK', 'The Inquisitr', 'The Manchested Evening News', 'The Week UK', 'Trump Times', 'Unian', 'Window on Eurasia Blog', 'Wizbang', 'rferl', 'theRussophileorg')\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LSPtieQaTX2",
        "colab_type": "code",
        "outputId": "1596c982-7730-4cef-f88e-60a25bf2f87c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "filtered_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>source</th>\n",
              "      <th>name</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>Addicting Info</td>\n",
              "      <td>Donald Trump Jr Likes Fox News Tweet About Spr...</td>\n",
              "      <td>Since Donald Trump Jr. has admitted on Twitter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>Addicting Info</td>\n",
              "      <td>REPORT UK Will Share Less Confidential Info Wi...</td>\n",
              "      <td>The Republican-written and Republican-altered ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>Addicting Info</td>\n",
              "      <td>Trump Jr Mocked To Oblivion After Democracy Di...</td>\n",
              "      <td>The world is still laughing at the Trump admin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>BBC</td>\n",
              "      <td>Battling to save the worlds bananas</td>\n",
              "      <td>Visiting the Matanuska banana plantation is no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>BBC</td>\n",
              "      <td>Escape from the asylum</td>\n",
              "      <td>In Croatia, thousands of people with mental il...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date  ...                                            content\n",
              "0  2018-02-01  ...  Since Donald Trump Jr. has admitted on Twitter...\n",
              "1  2018-02-01  ...  The Republican-written and Republican-altered ...\n",
              "2  2018-02-01  ...  The world is still laughing at the Trump admin...\n",
              "3  2018-02-01  ...  Visiting the Matanuska banana plantation is no...\n",
              "4  2018-02-01  ...  In Croatia, thousands of people with mental il...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZmXa1uFeZra",
        "colab_type": "code",
        "outputId": "b821c4ee-2b60-4edd-883d-451f28c248af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(filtered_data.shape)\n",
        "print(filtered_data.size)\n",
        "unique_sources = filtered_data.source.unique()\n",
        "for i in unique_sources:\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(622662, 4)\n",
            "2490648\n",
            "Addicting Info\n",
            "BBC\n",
            "Business Insider\n",
            "DC Gazette\n",
            "Daily Kos\n",
            "Daily Signal\n",
            "FiveThirtyEight\n",
            "Freedom Outpost\n",
            "FrontPage Magazine\n",
            "Fusion\n",
            "Glossy News\n",
            "Humor Times\n",
            "Infowars\n",
            "Intellectual Conservative\n",
            "Intellihub\n",
            "Investors Business Daily\n",
            "Observer\n",
            "Politico\n",
            "RT\n",
            "Slate\n",
            "The American Conservative\n",
            "The Atlantic\n",
            "The Chaser\n",
            "The Guardian\n",
            "The Political Insider\n",
            "The Shovel\n",
            "True Pundit\n",
            "Veterans Today\n",
            "The Washington Examiner\n",
            "Yahoo News\n",
            "Counter Current News\n",
            "Real News Right Now\n",
            "Salon\n",
            "The Borowitz Report\n",
            "The Spoof\n",
            "Waking Times\n",
            "Activist Post\n",
            "CBS News\n",
            "Media Matters for America\n",
            "Palmer Report\n",
            "Politicus USA\n",
            "The Beaverton\n",
            "Faking News\n",
            "News Busters\n",
            "Breitbart\n",
            "CNBC\n",
            "CNN\n",
            "Shadow Proof\n",
            "The Conservative Tree House\n",
            "The Gateway Pundit\n",
            "The Huffington Post\n",
            "The Michelle Malkin Blog\n",
            "USA Today\n",
            "Bipartisan Report\n",
            "CNS News\n",
            "Daily Mail\n",
            "Drudge Report\n",
            "NPR\n",
            "National Review\n",
            "Natural News\n",
            "New York Daily News\n",
            "New York Post\n",
            "News Biscuit\n",
            "RedState\n",
            "Shareblue\n",
            "Talking Points Memo\n",
            "Daily Beast\n",
            "The Daily Caller\n",
            "The New York Times\n",
            "The Right Scoop\n",
            "TheBlaze\n",
            "ThinkProgress\n",
            "Vox\n",
            "Bearing Arms\n",
            "Forward Progessives\n",
            "The Intercept\n",
            "Reuters\n",
            "RightWingWatch\n",
            "Hot Air\n",
            "Western Journal\n",
            "Conservative Home\n",
            "Instapundit\n",
            "Sputnik\n",
            "Crooks and Liars\n",
            "Raw Story\n",
            "Real Clear Politics\n",
            "The Verge\n",
            "iPolitics\n",
            "Buzzfeed\n",
            "NODISINFO\n",
            "Live Action\n",
            "Fox News\n",
            "The Hill\n",
            "Pamela Geller Report\n",
            "Fortune\n",
            "MSNBC\n",
            "oann\n",
            "Alternet\n",
            "Freedom Daily\n",
            "True Activist\n",
            "Interpreter Mag\n",
            "The Duran\n",
            "The Fiscal Times\n",
            "MotherJones\n",
            "PBS\n",
            "Washington Post\n",
            "ABC News\n",
            "ScrappleFace\n",
            "HumansAreFree\n",
            "The Moscow Times\n",
            "21stCenturyWire\n",
            "France24\n",
            "Pravada Report\n",
            "TheAntiMedia\n",
            "Foreign Policy\n",
            "LewRockwell\n",
            "Newsweek\n",
            "Russia-Insider\n",
            "Spiegel\n",
            "The Telegraph\n",
            "sott.net\n",
            "Evening Standard\n",
            "Politics UK\n",
            "The Daily Star\n",
            "The Guardian UK\n",
            "The Independent\n",
            "WSJ Washington Wire\n",
            "AMERICAblog News\n",
            "Wings Over Scotland\n",
            "The Onion\n",
            "Washington Monthly\n",
            "Chicago Sun-Times\n",
            "Feministing Blog\n",
            "Pink News UK\n",
            "The Poke\n",
            "Al Jazeera\n",
            "Birmingham Mail\n",
            "Mercury News\n",
            "Powerline Blog\n",
            "SkyNewsPolitics\n",
            "The Daily Express\n",
            "The Daily Mirror\n",
            "The Daily Record\n",
            "The Denver Post\n",
            "The Irish Times\n",
            "The Manchester Evening News\n",
            "The Sun\n",
            "SkyNewsUS\n",
            "Tass\n",
            "Telesur TV\n",
            "Prison Planet\n",
            "The D.C. Clothesline\n",
            "Democracy 21\n",
            "Daily Stormer\n",
            "FT Westminster Blog\n",
            "New Yorker\n",
            "GlobalResearch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKuGvitDB69W",
        "colab_type": "text"
      },
      "source": [
        "##Amalagamation\n",
        "Amalgamated dataset is available here: nela_aggregate_labels.csv (https://drive.google.com/open?id=1xHUgscjHWsPAuDocVqCF1ckfsI6KTt2k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moLebp8qnYR9",
        "colab_type": "text"
      },
      "source": [
        "### Load labels CSV with aggregated values\n",
        "\n",
        "Below is the approach followed for aggregation all labels in Label.csv:\n",
        "* Converted each score into the range of 1(bad) to 5(good)\n",
        "  * NewsGuard: ROUND(NewsGuard_Score/20))\n",
        "  * Pew Research: -1→ 1, 0 → 3, 1-->5\n",
        "  * Wikipedia 1-->1\n",
        "  * Open Sources : purple → 1, orange/gray → 3, green → 5\n",
        "  * Media Bias / Fact Check, factual_reporting → already in 1-5 range\n",
        "  * Politifact → consider all false as negative numbers and true as positives→ Round(((Sum_of_values+6)/8)*5)\n",
        "* **Aggregated score** = Sum_of_all_available_scores_for_source/number_of_scores_available\n",
        "\n",
        "All the calculations are available here: https://docs.google.com/spreadsheets/d/1yn0KaqP5b0WUJYNohy3fFXHxZiRRPEWcXiDbahvtETU/edit?usp=sharing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s1QU8SthLA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#aggregated_labels.csv: https://drive.google.com/open?id=1e_H3EaaSoupdnMTL132s6YyrwDvSR_Ib\n",
        "labels_filename = 'aggregated_labels.csv'\n",
        "for fname,fid in {\"aggregated_labels.csv\": \"1e_H3EaaSoupdnMTL132s6YyrwDvSR_Ib\"}.items():\n",
        "  downloaded = drive.CreateFile({'id':fid}) \n",
        "  downloaded.GetContentFile(fname)\n",
        "  aggregated_labels = pd.read_csv(labels_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlNOW12XiKLr",
        "colab_type": "code",
        "outputId": "c3f49345-8460-4b42-9211-9d1797de6d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "aggregated_labels.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>NewsGuard, Does not repeatedly publish false content</th>\n",
              "      <th>NewsGuard, Gathers and presents information responsibly</th>\n",
              "      <th>NewsGuard, Regularly corrects or clarifies errors</th>\n",
              "      <th>NewsGuard, Handles the difference between news and opinion responsibly</th>\n",
              "      <th>NewsGuard, Avoids deceptive headlines</th>\n",
              "      <th>NewsGuard, Website discloses ownership and financing</th>\n",
              "      <th>NewsGuard, Clearly labels advertising</th>\n",
              "      <th>NewsGuard, Reveals who's in charge, including any possible conflicts of interest</th>\n",
              "      <th>NewsGuard, Provides information about content creators</th>\n",
              "      <th>NewsGuard, score</th>\n",
              "      <th>(1-5) Score</th>\n",
              "      <th>NewsGuard, overall_class</th>\n",
              "      <th>Pew Research Center, known_by_40%</th>\n",
              "      <th>Pew Research Center, total</th>\n",
              "      <th>(1-5) Score.1</th>\n",
              "      <th>Pew Research Center, consistently_liberal</th>\n",
              "      <th>Pew Research Center, mostly_liberal</th>\n",
              "      <th>Pew Research Center, mixed</th>\n",
              "      <th>Pew Research Center, mostly conservative</th>\n",
              "      <th>Pew Research Center, consistently conservative</th>\n",
              "      <th>Wikipedia, is_fake</th>\n",
              "      <th>(1-5) Score.2</th>\n",
              "      <th>Open Sources, reliable</th>\n",
              "      <th>Open Sources, fake</th>\n",
              "      <th>Open Sources, unreliable</th>\n",
              "      <th>Open Sources, bias</th>\n",
              "      <th>Open Sources, conspiracy</th>\n",
              "      <th>Open Sources, hate</th>\n",
              "      <th>Open Sources, junksci</th>\n",
              "      <th>Open Sources, rumor</th>\n",
              "      <th>Open Sources, blog</th>\n",
              "      <th>Open Sources, clickbait</th>\n",
              "      <th>Open Sources, political</th>\n",
              "      <th>Open Sources, satire</th>\n",
              "      <th>Open Sources, state</th>\n",
              "      <th>Open Sources, aggregated fake</th>\n",
              "      <th>(1-5) Score.3</th>\n",
              "      <th>Media Bias / Fact Check, label</th>\n",
              "      <th>Media Bias / Fact Check, factual_reporting</th>\n",
              "      <th>Media Bias / Fact Check, extreme_left</th>\n",
              "      <th>Media Bias / Fact Check, right</th>\n",
              "      <th>Media Bias / Fact Check, extreme_right</th>\n",
              "      <th>Media Bias / Fact Check, propaganda</th>\n",
              "      <th>Media Bias / Fact Check, fake_news</th>\n",
              "      <th>Media Bias / Fact Check, some_fake_news</th>\n",
              "      <th>Media Bias / Fact Check, failed_fact_checks</th>\n",
              "      <th>Media Bias / Fact Check, conspiracy</th>\n",
              "      <th>Media Bias / Fact Check, pseudoscience</th>\n",
              "      <th>Media Bias / Fact Check, hate_group</th>\n",
              "      <th>Media Bias / Fact Check, anti_islam</th>\n",
              "      <th>Media Bias / Fact Check, nationalism</th>\n",
              "      <th>Allsides, bias_rating</th>\n",
              "      <th>Allsides, community_agree</th>\n",
              "      <th>Allsides, community_disagree</th>\n",
              "      <th>Allsides, community_label</th>\n",
              "      <th>BuzzFeed, leaning</th>\n",
              "      <th>PolitiFact, Pants on Fire!</th>\n",
              "      <th>PolitiFact, False</th>\n",
              "      <th>PolitiFact, Mostly False</th>\n",
              "      <th>PolitiFact, Half-True</th>\n",
              "      <th>PolitiFact, Mostly True</th>\n",
              "      <th>PolitiFact, True</th>\n",
              "      <th>PF (1-5) Score</th>\n",
              "      <th>aggregated</th>\n",
              "      <th>Unnamed: 65</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Beaverton</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>orange</td>\n",
              "      <td>3.0</td>\n",
              "      <td>satire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Infowars</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>purple</td>\n",
              "      <td>1.0</td>\n",
              "      <td>conspiracy_pseudoscience</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Right</td>\n",
              "      <td>3579.0</td>\n",
              "      <td>782.0</td>\n",
              "      <td>absolutely agree</td>\n",
              "      <td>right</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Breitbart</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>purple</td>\n",
              "      <td>1.0</td>\n",
              "      <td>questionable_source</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Right</td>\n",
              "      <td>11911.0</td>\n",
              "      <td>6546.0</td>\n",
              "      <td>agree</td>\n",
              "      <td>right</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Drudge Report</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>purple</td>\n",
              "      <td>1.0</td>\n",
              "      <td>right_bias</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Lean Right</td>\n",
              "      <td>1631.0</td>\n",
              "      <td>994.0</td>\n",
              "      <td>agree</td>\n",
              "      <td>right</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bipartisan Report</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>purple</td>\n",
              "      <td>1.0</td>\n",
              "      <td>questionable_source</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>left</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Source  ...  Unnamed: 65\n",
              "0      The Beaverton  ...          NaN\n",
              "1           Infowars  ...          NaN\n",
              "2          Breitbart  ...          NaN\n",
              "3      Drudge Report  ...          NaN\n",
              "4  Bipartisan Report  ...          NaN\n",
              "\n",
              "[5 rows x 66 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsCOpqZDnadB",
        "colab_type": "text"
      },
      "source": [
        "### Join Labels CSV with articles DB using \"Source\" as key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MMSB1SENDs-",
        "colab_type": "code",
        "outputId": "f845bc95-babf-4d39-9c36-070eaf67d341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import sqlite3\n",
        "\n",
        "#Make the db in memory\n",
        "conn = sqlite3.connect(':memory:')\n",
        "\n",
        "filtered_data.to_sql('data', conn, index=False)\n",
        "aggregated_labels.to_sql('label', conn, index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:2712: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGE0L1kTdBIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query = '''\n",
        "SELECT D.*, L.aggregated\n",
        "FROM data D JOIN label L ON D.source = L.Source\n",
        "'''\n",
        "\n",
        "aggr_df = pd.read_sql_query(query, conn)\n",
        "conn.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw6z3O-Of2uK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aggr_df.to_csv(\"nela_aggregate_labels.csv\", header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9FyCc7PeaaM",
        "colab_type": "code",
        "outputId": "c4c32e0f-bfdc-4dd8-94cd-9721093a05dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "!cp nela_aggregate_labels.csv drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80NzMr-3DDc4",
        "colab_type": "text"
      },
      "source": [
        "##Data Filteration\n",
        "\n",
        "The NELA dataset is very big in size ~700K. The next challenge was to reduce it to ~20k with even distribution of labels and all available sources. Below is the approach followed for it:\n",
        "\n",
        "- There are total 5 labels : 1 (Pants-on-fire) to 5 (True)\n",
        "- Count number of sources for each label\n",
        "- No. of articles per label = total dataset size(20k) / no_of_labels(5) = 4000\n",
        "- Articles per source = 4000/no_of_articles_for_label\n",
        "\n",
        "The calculation is shown below and programmed using SQL queries:\n",
        "\n",
        "\n",
        "| Label | 1 | 2 | 3 | 4 | 5|\n",
        "| --- | ---| ---| ---| ---| ---|\n",
        "| No_of_sources | 14| 31| 33| 45| 27|\n",
        "| articles_per_source | 4000/14=286 | 4000/31=129| 4000/33=121| 4000/45=89| 4000/27=148|\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N_epYHzenv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioVNJ2Hme9Zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_id = '1vqknNKpwpe8OsvPMaTJvMNsczdV4owHk'\n",
        "downloaded = drive.CreateFile({'id':file_id}) \n",
        "downloaded.GetContentFile('nela_aggregate_labels.csv') \n",
        "data_in = pd.read_csv('nela_aggregate_labels.csv')\n",
        "data_in.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9isO5Z6hH2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conn = sqlite3.connect(':memory:')\n",
        "aggr_df.to_sql('aggregate', conn, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiQ1ywduLeHa",
        "colab_type": "text"
      },
      "source": [
        "###SQL query to filter data as per equation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5VT00wuRxEz",
        "colab_type": "text"
      },
      "source": [
        "`data_filtering` function is used for filtering data for each label (1-5) and evenly selecting data for each source present for that label. The function constructs a `UNION` of multiple queries that get detail for each source."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm8A3sddN1T_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_filtering(sources, label, limit):\n",
        "  query = '''SELECT * FROM ( SELECT * FROM aggregate X\n",
        "  WHERE ROUND(X.aggregated) = {arg} AND source = \"{src}\" LIMIT 0, {lmt})\n",
        "  '''\n",
        "  query_parts = []\n",
        "  for source in sources: \n",
        "    query_parts.append(query.format(arg=label, src=source, lmt=limit))\n",
        "\n",
        "  query = \" UNION \".join(query_parts)\n",
        "  df = pd.read_sql_query(query, conn)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNlQuX1hLi-U",
        "colab_type": "text"
      },
      "source": [
        "### Filter articles having label as 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42M5EcUwkCa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LABEL 1\n",
        "sources = [\"DC Gazette\",\n",
        "            \"Daily Stormer\",\n",
        "            \"Faking News\",\n",
        "            \"Freedom Outpost\",\n",
        "            \"FrontPage Magazine\",\n",
        "            \"LewRockwell\",\n",
        "            \"Real News Right Now\",\n",
        "            \"The D.C. Clothesline\",\n",
        "            \"The Duran\",\n",
        "            \"True Activist\",\n",
        "            \"Pamela Geller Report\",\n",
        "            \"The Conservative Tree House\",\n",
        "            \"Infowars\",\n",
        "            \"Bipartisan Report\" ]\n",
        "            \n",
        "df = data_filtering(sources, 1, 300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlRgxwSmRQWy",
        "colab_type": "code",
        "outputId": "12f2e655-0f5e-4e01-8cd1-71211243b931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(df.shape)\n",
        "df.head()\n",
        "df.to_csv(\"nela_score_1_values.csv\", header=True)\n",
        "!cp nela_score_1_values.csv drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3718, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>source</th>\n",
              "      <th>name</th>\n",
              "      <th>content</th>\n",
              "      <th>aggregated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>DC Gazette</td>\n",
              "      <td>SHOCKER Key GOP House Member TREY GOWDY Not Se...</td>\n",
              "      <td>It wasnt exactly widely known, but South Carol...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>DC Gazette</td>\n",
              "      <td>Saudi Arabia Seizes BILLIONS In Anti-Corruptio...</td>\n",
              "      <td>Amazing what happens when a government activel...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>Freedom Outpost</td>\n",
              "      <td>10 Amazing Facts About Americas Economic Recov...</td>\n",
              "      <td>If the U.S. economy continues to surge under P...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>Freedom Outpost</td>\n",
              "      <td>Democrats Have Absolutely No Class They Put It...</td>\n",
              "      <td>After observing the despicable behavior of the...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>Freedom Outpost</td>\n",
              "      <td>ReleaseTheMemo Even Democrats Are Admitting Th...</td>\n",
              "      <td>Never before has there been so much talk about...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date  ... aggregated\n",
              "0  2018-02-01  ...        1.0\n",
              "1  2018-02-01  ...        1.0\n",
              "2  2018-02-01  ...        1.0\n",
              "3  2018-02-01  ...        1.0\n",
              "4  2018-02-01  ...        1.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyrfHANoLqDB",
        "colab_type": "text"
      },
      "source": [
        "### Filter articles having label as 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0xxjcsSjCo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LABEL 2\n",
        "sources = [\"Freedom Daily\",\n",
        "          \"Natural News\",\n",
        "          \"Activist Post\",\n",
        "          \"HumansAreFree\",\n",
        "          \"Instapundit\",\n",
        "          \"Intellihub\",\n",
        "          \"NODISINFO\",\n",
        "          \"Prison Planet\",\n",
        "          \"Waking Times\",\n",
        "          \"GlobalResearch\",\n",
        "          \"Live Action\",\n",
        "          \"Palmer Report\",\n",
        "          \"Sputnik\",\n",
        "          \"TheAntiMedia\",\n",
        "          \"Drudge Report\",\n",
        "          \"Daily Mail\",\n",
        "          \"The Gateway Pundit\",\n",
        "          \"Addicting Info\",\n",
        "          \"CNS News\",\n",
        "          \"Counter Current News\",\n",
        "          \"Pravada Report\",\n",
        "          \"RedState\",\n",
        "          \"Russia-Insider\",\n",
        "          \"Shareblue\",\n",
        "          \"The Daily Express\",\n",
        "          \"The Right Scoop\",\n",
        "          \"Veterans Today\",\n",
        "          \"Western Journal\",\n",
        "          \"21stCenturyWire\",\n",
        "          \"Breitbart\",\n",
        "          \"True Pundit\"]\n",
        "\n",
        "df = data_filtering(sources, 2, 150)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyXUdi4ykVep",
        "colab_type": "code",
        "outputId": "bf419482-1568-4660-96d8-4622831aa411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(df.shape)\n",
        "df.head()\n",
        "df.to_csv(\"nela_score_2_values.csv\", header=True)\n",
        "!cp nela_score_2_values.csv drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4168, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNsC4-UqLtOg",
        "colab_type": "text"
      },
      "source": [
        "### Filter articles having label as 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkRqw1HFkxlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LABEL 3\n",
        "sources = [\"The Beaverton\",\n",
        "          \"The Political Insider\",\n",
        "          \"Daily Kos\",\n",
        "          \"RT\",\n",
        "          \"Politicus USA\",\n",
        "          \"The Daily Caller\",\n",
        "          \"TheBlaze\",\n",
        "          \"Raw Story\",\n",
        "          \"Al Jazeera\",\n",
        "          \"AMERICAblog News\",\n",
        "          \"Glossy News\",\n",
        "          \"Humor Times\",\n",
        "          \"News Biscuit\",\n",
        "          \"ScrappleFace\",\n",
        "          \"The Borowitz Report\",\n",
        "          \"The Chaser\",\n",
        "          \"The Onion\",\n",
        "          \"The Poke\",\n",
        "          \"The Shovel\",\n",
        "          \"The Spoof\",\n",
        "          \"Daily Signal\",\n",
        "          \"FT Westminster Blog\",\n",
        "          \"Birmingham Mail\",\n",
        "          \"Feministing Blog\",\n",
        "          \"News Busters\",\n",
        "          \"RightWingWatch\",\n",
        "          \"sott.net\",\n",
        "          \"Telesur TV\",\n",
        "          \"The Daily Mirror\",\n",
        "          \"The Daily Record\",\n",
        "          \"The Daily Star\",\n",
        "          \"The Sun\",\n",
        "          \"New York Post\" ]\n",
        "\n",
        "df = data_filtering(sources, 3, 130)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e-65doplf7s",
        "colab_type": "code",
        "outputId": "772cce26-8deb-4186-85bf-1613a1352908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(df.shape)\n",
        "df.head()\n",
        "df.to_csv(\"nela_score_3_values.csv\", header=True)\n",
        "!cp nela_score_3_values.csv drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3824, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkPXz_L-Lu6S",
        "colab_type": "text"
      },
      "source": [
        "### Filter articles having label as 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SzvpSttkzRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LABEL 4\n",
        "sources = [ \"The Washington Examiner\",\n",
        "          \"Buzzfeed\",\n",
        "          \"ThinkProgress\",\n",
        "          \"Observer\",\n",
        "          \"Bearing Arms\",\n",
        "          \"Crooks and Liars\",\n",
        "          \"New York Daily News\",\n",
        "          \"The Intercept\",\n",
        "          \"MotherJones\",\n",
        "          \"The Huffington Post\",\n",
        "          \"CNN\",\n",
        "          \"Fox News\",\n",
        "          \"Investors Business Daily\",\n",
        "          \"Newsweek\",\n",
        "          \"National Review\",\n",
        "          \"Fusion\",\n",
        "          \"Alternet\",\n",
        "          \"Daily Beast\",\n",
        "          \"Slate\",\n",
        "          \"Democracy 21\",\n",
        "          \"Evening Standard\",\n",
        "          \"Foreign Policy\",\n",
        "          \"Forward Progessives\",\n",
        "          \"France24\",\n",
        "          \"Hot Air\",\n",
        "          \"Interpreter Mag\",\n",
        "          \"iPolitics\",\n",
        "          \"Media Matters for America\",\n",
        "          \"Pink News UK\",\n",
        "          \"Salon\",\n",
        "          \"Shadow Proof\",\n",
        "          \"SkyNewsPolitics\",\n",
        "          \"SkyNewsUS\",\n",
        "          \"Spiegel\",\n",
        "          \"Talking Points Memo\",\n",
        "          \"Tass\",\n",
        "          \"The Fiscal Times\",\n",
        "          \"The Independent\",\n",
        "          \"The Irish Times\",\n",
        "          \"The Moscow Times\",\n",
        "          \"The Telegraph\",\n",
        "          \"Wings Over Scotland\",\n",
        "          \"MSNBC\",\n",
        "          \"The New York Times\",\n",
        "          \"Yahoo News\" ]\n",
        "\n",
        "df = data_filtering(sources, 4, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG35KDu1lhT5",
        "colab_type": "code",
        "outputId": "f05c9331-a485-4010-ab94-e1f9e34f3533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(df.shape)\n",
        "df.head()\n",
        "df.to_csv(\"nela_score_4_values.csv\", header=True)\n",
        "!cp nela_score_4_values.csv drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4352, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqqZX_GFLzfE",
        "colab_type": "text"
      },
      "source": [
        "### Filter articles having label as 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvc48IPAk6ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LABEL 5\n",
        "sources = [\"Business Insider\",\n",
        "          \"Chicago Sun-Times\",\n",
        "          \"CNBC\",\n",
        "          \"FiveThirtyEight\",\n",
        "          \"Fortune\",\n",
        "          \"Mercury News\",\n",
        "          \"Real Clear Politics\",\n",
        "          \"The American Conservative\",\n",
        "          \"The Atlantic\",\n",
        "          \"The Denver Post\",\n",
        "          \"The Hill\",\n",
        "          \"The Verge\",\n",
        "          \"Vox\",\n",
        "          \"Washington Monthly\",\n",
        "          \"ABC News\",\n",
        "          \"BBC\",\n",
        "          \"CBS News\",\n",
        "          \"New Yorker\",\n",
        "          \"PBS\",\n",
        "          \"Politico\",\n",
        "          \"The Guardian\",\n",
        "          \"USA Today\",\n",
        "          \"Washington Post\",\n",
        "          \"oann\",\n",
        "          \"NPR\",\n",
        "          \"Reuters\",\n",
        "          \"WSJ Washington Wire\"]\n",
        "df = data_filtering(sources, 5, 150)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wXyWgJFliUo",
        "colab_type": "code",
        "outputId": "4499a7bd-0a06-4830-dd00-e300bf494b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(df.shape)\n",
        "df.head()\n",
        "df.to_csv(\"nela_score_5_values.csv\", header=True)\n",
        "!cp nela_score_5_values.csv drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3979, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGY8pONLSUP5",
        "colab_type": "text"
      },
      "source": [
        "### Generate a single dataset with evenly distributed labels\n",
        "\n",
        "The goal of filtering was to generate a subset of NELA dataset that has evenly distributed data for each label. After retrieving data for each label, all datasets that were generated must be merged into one. Below code performs that and creates a single `nela_score_values_reduced_ds.csv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GowPRta7m6u4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfs = []\n",
        "for i in range(1, 6):\n",
        "  dfs.append(pd.read_csv(\"nela_score_{}_values.csv\".format(i)))\n",
        "master_df = pd.concat(dfs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsZhoC4FnYaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "master_df.to_csv(\"nela_score_values_reduced_ds.csv\", header=True)\n",
        "!cp nela_score_values_reduced_ds.csv drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}